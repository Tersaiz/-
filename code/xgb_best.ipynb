{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import copy as cp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cbt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,log_loss\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime,timedelta\n",
    "import warnings\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy as cp\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('../data_3/second_round_training_data.csv')[['Parameter'+str(i) for i in range(1,11)]+['Quality_label']]\n",
    "# test = pd.read_csv('../data_3/second_round_testing_data.csv')\n",
    "# submit = pd.read_csv('../data_3/submit_example2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = pd.read_csv('../data/first_round_training_data.csv')[['Parameter'+str(i) for i in range(1,11)]+['Quality_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_1,train_2],sort = False)\n",
    "test = pd.read_csv('../data_3/second_round_testing_data_2.csv')\n",
    "submit = pd.read_csv('../data_3/submit_example2.csv')\n",
    "\n",
    "#train = train.drop_duplicates(['Parameter5','Parameter7','Parameter8','Parameter9','Parameter10','Attribute4','Attribute5','Attribute6','Attribute7','Attribute8','Attribute9','Attribute10'],'first')\n",
    "#来做特征啦啦\n",
    "data = train.append(test,sort=False).reset_index(drop=True)\n",
    "dit = {'Excellent':0,'Good':1,'Pass':2,'Fail':3}\n",
    "data['label'] = data['Quality_label'].map(dit)\n",
    "train['label'] = train['Quality_label'].map(dit)\n",
    "del data['Quality_label']\n",
    "data = data.fillna(-1)\n",
    "\n",
    "\n",
    "# data['moby6'] = data['Parameter5']/(data['Parameter6']+data['Parameter7']+data['Parameter8']+data['Parameter9']+data['Parameter10'])#太完美了\n",
    "# data['moby7'] = (data['Parameter5']+data['Parameter6'])/(data['Parameter7']+data['Parameter8']+data['Parameter9']+data['Parameter10'])\n",
    "# data['moby8'] = data['Parameter8']/(data['Parameter5']+data['Parameter6']+data['Parameter7']+data['Parameter8']+data['Parameter9']+data['Parameter10'])\n",
    "\n",
    "#略有用，重复度计数\n",
    "# m = data.groupby(['Parameter6'])['label'].count().reset_index(name='count6')\n",
    "# data = pd.merge(data,m,on ='Parameter6',how = 'left' )\n",
    "\n",
    "# m = data.groupby(['Parameter7'])['label'].count().reset_index(name='count7')\n",
    "# data = pd.merge(data,m,on ='Parameter7',how = 'left' )\n",
    "# m = data.groupby(['Parameter8'])['label'].count().reset_index(name='count8')\n",
    "# data = pd.merge(data,m,on ='Parameter8',how = 'left' )\n",
    "# # m = data.groupby(['Parameter9'])['label'].count().reset_index(name='count9')\n",
    "# # data = data.merge(m)\n",
    "# m = data.groupby(['Parameter10'])['label'].count().reset_index(name='count10')\n",
    "# data = pd.merge(data,m,on ='Parameter10',how = 'left' )\n",
    "\n",
    "# m = data.groupby(['Parameter10'])['label'].mean().rank().reset_index(name='rank')\n",
    "# data = pd.merge(data,m,on ='Parameter10',how = 'left' )\n",
    "\n",
    "# data['moby1'] = data['Parameter7']/(data['Parameter5']+data['Parameter6']+data['Parameter8'])\n",
    "# # data['moby2'] = data['Parameter10']/(data['Parameter5']+data['Parameter6']+data['Parameter8']+data['Parameter9'])\n",
    "# # data['moby3'] = data['Parameter8']/(data['Parameter5']+data['Parameter6']+data['Parameter7']+data['Parameter8']+data['Parameter9']+data['Parameter10'])\n",
    "# # data['moby6'] = (data['Parameter5']+data['Parameter6'])/(data['Parameter9'])\n",
    "# #0.6985\n",
    "\n",
    "\n",
    "# # data['moby11'] =data['Parameter5']/data['Parameter9']  0.6971\n",
    "# # data['moby13'] =data['Parameter6']/data['Parameter5']  0.6966\n",
    "# # data['moby14'] =data['Parameter6']/data['Parameter7']  0.684\n",
    "# # data['moby16'] =data['Parameter6']/data['Parameter9']  \n",
    "# # 0.69966 目前最高\n",
    "\n",
    "\n",
    "# data['moby20'] =data['Parameter7']/data['Parameter8']\n",
    "\n",
    "# # data['moby21'] =data['Parameter7']/data['Parameter9']\n",
    "\n",
    "# # data['p5_6'] = data['Parameter5'].astype(str)+'_'+data['Parameter6'].astype(str)\n",
    "# # lbl = LabelEncoder()\n",
    "# # lbl.fit(list(data['p5_6'].values))\n",
    "# # data['p5_6'] = lbl.transform(list(data['p5_6'].values))\n",
    "\n",
    "\n",
    "data = data.fillna(-1)\n",
    "train = data.loc[data.label>=0]\n",
    "test = data.loc[data.label<0]\n",
    "# test = test.sort_values(by=['Group'], ascending=True)\n",
    "label = train['label']\n",
    "# feature = [f for f in data.columns if f not in ['label','Group','Parameter1','Parameter2','Parameter3','Parameter4']]\n",
    "feature = [f for f in data.columns if f not in ['label','Group']]\n",
    "\n",
    "train_x = train[feature]\n",
    "train_y = train['label'].astype(np.int32)\n",
    "\n",
    "test_id = test['Group']\n",
    "test_x = test[feature].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167898</td>\n",
       "      <td>104.443982</td>\n",
       "      <td>2.772825</td>\n",
       "      <td>0.146548</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252.483066</td>\n",
       "      <td>0.343232</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.124654</td>\n",
       "      <td>0.170534</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294.656750</td>\n",
       "      <td>6.153711</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>4284.326273</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026284</td>\n",
       "      <td>0.166810</td>\n",
       "      <td>7.587398</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3   Parameter4  Parameter5  Parameter6  \\\n",
       "0    0.167898  104.443982    2.772825     0.146548    0.000421    0.000612   \n",
       "1  252.483066    0.343232    0.066873     0.002495    0.000909    0.002397   \n",
       "2    4.124654    0.170534    0.383800     0.000004    0.000909    0.001972   \n",
       "3  294.656750    6.153711    0.014716  4284.326273    0.000909    0.002397   \n",
       "4    0.026284    0.166810    7.587398     0.002202    0.000909    0.002397   \n",
       "\n",
       "    Parameter7  Parameter8  Parameter9  Parameter10  \n",
       "0  2286.523413    0.035407    0.593081     1.010385  \n",
       "1  2286.523413    0.035407    0.593081     1.010385  \n",
       "2  2286.523413    0.035407    0.593081     1.010385  \n",
       "3  2286.523413    0.035407    0.593081     1.010385  \n",
       "4  2286.523413    0.035407    0.593081     1.010385  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007218</td>\n",
       "      <td>5.081092</td>\n",
       "      <td>1.132919</td>\n",
       "      <td>931.721241</td>\n",
       "      <td>2.225808</td>\n",
       "      <td>2.208755</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527218</td>\n",
       "      <td>0.025262</td>\n",
       "      <td>1.049852</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>4.803947</td>\n",
       "      <td>3.965023</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>0.377332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004863</td>\n",
       "      <td>85.700444</td>\n",
       "      <td>4.002861</td>\n",
       "      <td>1.443409</td>\n",
       "      <td>4.803947</td>\n",
       "      <td>3.965023</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>0.377332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.387838</td>\n",
       "      <td>2.456417</td>\n",
       "      <td>8.820446</td>\n",
       "      <td>0.408974</td>\n",
       "      <td>2.484379</td>\n",
       "      <td>3.965023</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>0.377332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.355337</td>\n",
       "      <td>0.076572</td>\n",
       "      <td>23.199547</td>\n",
       "      <td>1.172201</td>\n",
       "      <td>3.095123</td>\n",
       "      <td>2.684398</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>2.005852</td>\n",
       "      <td>0.377332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0    0.007218    5.081092    1.132919  931.721241    2.225808    2.208755   \n",
       "1    0.527218    0.025262    1.049852    0.050764    4.803947    3.965023   \n",
       "2    0.004863   85.700444    4.002861    1.443409    4.803947    3.965023   \n",
       "3    5.387838    2.456417    8.820446    0.408974    2.484379    3.965023   \n",
       "4    3.355337    0.076572   23.199547    1.172201    3.095123    2.684398   \n",
       "\n",
       "   Parameter7  Parameter8  Parameter9  Parameter10  \n",
       "0    0.038483    2.931083    6.783967     1.010385  \n",
       "1    0.038483    2.931083    6.783967     0.377332  \n",
       "2    0.038483    2.931083    6.783967     0.377332  \n",
       "3    0.038483    2.931083    6.783967     0.377332  \n",
       "4    0.038483    2.931083    2.005852     0.377332  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['Parameter1'] = np.log(train_x['Parameter1']+1e-05).round(3)\n",
    "train_x['Parameter2'] = np.log(train_x['Parameter2']+1e-05).round(3)\n",
    "train_x['Parameter3'] = np.log(train_x['Parameter3']+1e-05).round(3)\n",
    "train_x['Parameter4'] = np.log(train_x['Parameter4']+1e-05).round(3)\n",
    "\n",
    "\n",
    "test_x['Parameter1'] = np.log(test_x['Parameter1']+1e-05).round(3)\n",
    "test_x['Parameter2'] = np.log(test_x['Parameter2']+1e-05).round(3)\n",
    "test_x['Parameter3'] = np.log(test_x['Parameter3']+1e-05).round(3)\n",
    "test_x['Parameter4'] = np.log(test_x['Parameter4']+1e-05).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证ｘｇｂ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n 1\n",
      "[0]\ttrain-merror:0.347594\tvalidation-merror:0.484552\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 100 rounds.\n",
      "[100]\ttrain-merror:0.258665\tvalidation-merror:0.44864\n",
      "[200]\ttrain-merror:0.227306\tvalidation-merror:0.448376\n",
      "Stopping. Best iteration:\n",
      "[106]\ttrain-merror:0.257477\tvalidation-merror:0.446792\n",
      "\n",
      "fold n 2\n",
      "[0]\ttrain-merror:0.352083\tvalidation-merror:0.467917\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 100 rounds.\n",
      "[100]\ttrain-merror:0.267578\tvalidation-merror:0.44019\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-merror:0.292071\tvalidation-merror:0.434645\n",
      "\n",
      "fold n 3\n",
      "[0]\ttrain-merror:0.344491\tvalidation-merror:0.494851\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 100 rounds.\n",
      "[100]\ttrain-merror:0.255298\tvalidation-merror:0.465276\n",
      "Stopping. Best iteration:\n",
      "[21]\ttrain-merror:0.281046\tvalidation-merror:0.463692\n",
      "\n",
      "fold n 4\n",
      "[0]\ttrain-merror:0.352413\tvalidation-merror:0.466332\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 100 rounds.\n",
      "[100]\ttrain-merror:0.259853\tvalidation-merror:0.452073\n",
      "Stopping. Best iteration:\n",
      "[13]\ttrain-merror:0.296164\tvalidation-merror:0.445999\n",
      "\n",
      "fold n 5\n",
      "[0]\ttrain-merror:0.35305\tvalidation-merror:0.468304\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 100 rounds.\n",
      "[100]\ttrain-merror:0.261949\tvalidation-merror:0.446646\n",
      "[200]\ttrain-merror:0.231516\tvalidation-merror:0.445325\n",
      "Stopping. Best iteration:\n",
      "[115]\ttrain-merror:0.257394\tvalidation-merror:0.44374\n",
      "\n",
      "logloss 1.1413124171767046\n",
      "ac 0.5495405091370023\n",
      "mae 0.018924201143794755\n"
     ]
    }
   ],
   "source": [
    "tmp_pre = np.zeros((len(test_x),4))\n",
    "sub1 = pd.DataFrame()\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=False, random_state=2019)\n",
    "oof = np.zeros([train_x.shape[0],4])\n",
    "predictions = np.zeros([test_x.shape[0],4])\n",
    "\n",
    "param = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'multi:softprob',  # 多分类的问题\n",
    "        'num_class': 4,               # 类别数，与 multisoftmax 并用\n",
    "        'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "        'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "        'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "        'subsample': 0.9,              # 随机采样训练样本\n",
    "        'colsample_bytree': 0.9,       # 生成树时进行的列采样\n",
    "        'min_child_weight': 3,\n",
    "        'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "        'eta': 0.007,                  # 如同学习率\n",
    "        'seed': 112211,\n",
    "        'nthread': 6,                  # cpu 线程数\n",
    "    }\n",
    "\n",
    "# test_x = xgb.DMatrix(test_x)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x, train_y)):\n",
    "        print(\"fold n {}\".format(fold_+1))\n",
    "        \n",
    "        tr_x,tr_y = train_x.iloc[trn_idx],train_y.iloc[trn_idx]\n",
    "        va_x,va_y = train_x.iloc[val_idx],train_y.iloc[val_idx]\n",
    "        \n",
    "        \n",
    "        xg_train = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        xg_val = xgb.DMatrix(va_x,label=va_y)\n",
    "        \n",
    "        watchlist = [ (xg_train,'train'), (xg_val, 'validation') ]\n",
    "        \n",
    "        num_round = 1000\n",
    "        bst = xgb.train(param, xg_train, num_round, watchlist ,verbose_eval=100,early_stopping_rounds=100);\n",
    "        \n",
    "        \n",
    "        # get prediction\n",
    "        oof[val_idx] = bst.predict( xgb.DMatrix(va_x) )\n",
    "    #     prediction_xgb += bst.predict( test_x )/5\n",
    "\n",
    "        predictions = bst.predict( xgb.DMatrix(test_x) )/5 +predictions\n",
    "        \n",
    "#         print(np.corrcoef(predictions[:,0],tmp_pre[:,0] ) )  ##比较不同种子下相似度 0.991 lgb模型相似度可能高些\n",
    "\n",
    "#         tmp_pre = bst.predict( xgb.DMatrix(test_x) )\n",
    "\n",
    "\n",
    "#         sub = test[['Group']]\n",
    "#         prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "#         for i, f in enumerate(prob_cols):\n",
    "#             sub[f] = predictions[:, i]\n",
    "#         sub1 = pd.concat([sub,sub1],sort = False)    \n",
    "\n",
    "print('logloss',log_loss(pd.get_dummies(train_y).values, oof))\n",
    "print('ac',accuracy_score(train_y, np.argmax(oof,axis=1)))\n",
    "print('mae',1/(1 + np.sum(np.absolute(np.eye(4)[train_y] - oof))/480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思路：线下随机构造groupid，然后获得线下验证策略。\n",
    "def gen_sample(data, group_values, seed=0):\n",
    "    group_values = shuffle(group_values, random_state=seed)\n",
    "    # Group id 由group的值，做打乱获得，这里保存seed 信息，方便复现，因为有seed的话，就可以复现指定group\n",
    "    data['Group'] = seed * 1000 + group_values\n",
    "    return data\n",
    "\n",
    "\n",
    "group_values = test.Group.values.copy()\n",
    "data_2 = predictions.copy()\n",
    "# 随机10组验证，道理上组数越多方差越小，越稳定\n",
    "#for i in range(1, 10):\n",
    "#    data_2 = pd.concat([\n",
    "#        gen_sample(data[~data.label.isnull()], group_values, i),\n",
    "#        data_2], ignore_index=True\n",
    "#    )\n",
    "#    print(i, data_2.shape)\n",
    "\n",
    "#data_3 = data_2.groupby(['Group'], as_index=False)[bin_label + pred_label].mean()\n",
    "#print(\n",
    "#    'score:',\n",
    "#    1 / (1 + 10 * abs(\n",
    "#        data_3[data_3.Group >= 120][pred_label].values - data_3[data_3.Group >= 120][bin_label].values).mean())\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28259293, 0.25881191, 0.27303635, 0.18555883],\n",
       "       [0.29387285, 0.2469029 , 0.27838651, 0.18083774],\n",
       "       [0.27385631, 0.25872677, 0.27197799, 0.19543894],\n",
       "       ...,\n",
       "       [0.20395142, 0.3866783 , 0.19433199, 0.21503829],\n",
       "       [0.18923404, 0.35260142, 0.20113335, 0.25703119],\n",
       "       [0.22100769, 0.34876471, 0.26775216, 0.16247545]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv('../data_3/second_round_testing_data.csv')\n",
    "submit = pd.read_csv('../data_3/submit_example2.csv')\n",
    "sub = test_sub[['Group']]\n",
    "prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "\n",
    "for i, f in enumerate(prob_cols):\n",
    "    sub[f] = predictions[:, i]\n",
    "for i in prob_cols:\n",
    "    sub[i] = sub.groupby('Group')[i].transform('mean')\n",
    "sub = sub.drop_duplicates()\n",
    "# sub.to_csv(\"result_3/xgb_8.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"result_3/xgb_8.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(prob_cols):\n",
    "    sub1[f+'_rank'] = sub1.groupby('Group')[f].rank(method='first')\n",
    "    sub1[f+'_rank'] = sub1[f+'_rank']-125\n",
    "    sub1[f+'_rank'] = sub1[f+'_rank'].apply(lambda x: -(0.8/125/125/250)*x*x+1.4/250 )\n",
    "    sub1[f+'_rank'] = sub1[f+'_rank']  #*sub['gcnt']\n",
    "    sub1[f] = sub1[f]*sub1[f+'_rank']\n",
    "for i in prob_cols:\n",
    "    sub1[i] = sub1.groupby('Group')[i].transform('sum')  \n",
    "sub1 = sub1[list(submit)].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1['all_sum'] = sub1[prob_cols].sum(axis=1)\n",
    "for i in prob_cols:\n",
    "    sub1[i] = sub1[i]/sub1['all_sum']\n",
    "sub1['Group'] = submit['Group']\n",
    "sub1[list(submit)].to_csv('result_3/xgb_3.csv',index=False) ###0.70104530000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无限过过拟合训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.351009\ttrain-merror:0.351009\n",
      "[100]\ttrain-merror:0.272578\ttrain-merror:0.272578\n",
      "[200]\ttrain-merror:0.242421\ttrain-merror:0.242421\n",
      "[300]\ttrain-merror:0.214799\ttrain-merror:0.214799\n",
      "[400]\ttrain-merror:0.190715\ttrain-merror:0.190715\n",
      "[500]\ttrain-merror:0.172758\ttrain-merror:0.172758\n",
      "[600]\ttrain-merror:0.159079\ttrain-merror:0.159079\n",
      "[700]\ttrain-merror:0.147565\ttrain-merror:0.147565\n",
      "[800]\ttrain-merror:0.136633\ttrain-merror:0.136633\n",
      "[900]\ttrain-merror:0.126439\ttrain-merror:0.126439\n",
      "[1000]\ttrain-merror:0.116087\ttrain-merror:0.116087\n",
      "[1100]\ttrain-merror:0.107267\ttrain-merror:0.107267\n",
      "[1199]\ttrain-merror:0.098764\ttrain-merror:0.098764\n",
      "[[ 1. nan]\n",
      " [nan nan]]\n",
      "logloss 0.5252485757488436\n",
      "ac 0.9012358719763388\n",
      "mae 0.03257245705491214\n",
      "[0]\ttrain-merror:0.353227\ttrain-merror:0.353227\n",
      "[100]\ttrain-merror:0.273371\ttrain-merror:0.273371\n",
      "[200]\ttrain-merror:0.242738\ttrain-merror:0.242738\n",
      "[300]\ttrain-merror:0.215644\ttrain-merror:0.215644\n",
      "[400]\ttrain-merror:0.190768\ttrain-merror:0.190768\n",
      "[500]\ttrain-merror:0.172969\ttrain-merror:0.172969\n",
      "[600]\ttrain-merror:0.158815\ttrain-merror:0.158815\n",
      "[700]\ttrain-merror:0.146826\ttrain-merror:0.146826\n",
      "[800]\ttrain-merror:0.13658\ttrain-merror:0.13658\n",
      "[900]\ttrain-merror:0.12607\ttrain-merror:0.12607\n",
      "[1000]\ttrain-merror:0.116404\ttrain-merror:0.116404\n",
      "[1100]\ttrain-merror:0.107531\ttrain-merror:0.107531\n",
      "[1199]\ttrain-merror:0.098553\ttrain-merror:0.098553\n",
      "[[1.        0.9981379]\n",
      " [0.9981379 1.       ]]\n",
      "logloss 0.5240841990128613\n",
      "ac 0.9014471321432344\n",
      "mae 0.032616969997847155\n",
      "[0]\ttrain-merror:0.356026\ttrain-merror:0.356026\n",
      "[100]\ttrain-merror:0.271945\ttrain-merror:0.271945\n",
      "[200]\ttrain-merror:0.24221\ttrain-merror:0.24221\n",
      "[300]\ttrain-merror:0.215644\ttrain-merror:0.215644\n",
      "[400]\ttrain-merror:0.191296\ttrain-merror:0.191296\n",
      "[500]\ttrain-merror:0.173761\ttrain-merror:0.173761\n",
      "[600]\ttrain-merror:0.158762\ttrain-merror:0.158762\n",
      "[700]\ttrain-merror:0.146562\ttrain-merror:0.146562\n",
      "[800]\ttrain-merror:0.135946\ttrain-merror:0.135946\n",
      "[900]\ttrain-merror:0.125805\ttrain-merror:0.125805\n",
      "[1000]\ttrain-merror:0.115665\ttrain-merror:0.115665\n",
      "[1100]\ttrain-merror:0.107743\ttrain-merror:0.107743\n",
      "[1199]\ttrain-merror:0.099556\ttrain-merror:0.099556\n",
      "[[1.         0.99810372]\n",
      " [0.99810372 1.        ]]\n",
      "logloss 0.5242961857814565\n",
      "ac 0.9004436463504806\n",
      "mae 0.03261843449146243\n",
      "[0]\ttrain-merror:0.356502\ttrain-merror:0.356502\n",
      "[100]\ttrain-merror:0.273107\ttrain-merror:0.273107\n",
      "[200]\ttrain-merror:0.242315\ttrain-merror:0.242315\n",
      "[300]\ttrain-merror:0.214588\ttrain-merror:0.214588\n",
      "[400]\ttrain-merror:0.19193\ttrain-merror:0.19193\n",
      "[500]\ttrain-merror:0.173181\ttrain-merror:0.173181\n",
      "[600]\ttrain-merror:0.159343\ttrain-merror:0.159343\n",
      "[700]\ttrain-merror:0.14746\ttrain-merror:0.14746\n",
      "[800]\ttrain-merror:0.1379\ttrain-merror:0.1379\n",
      "[900]\ttrain-merror:0.125805\ttrain-merror:0.125805\n",
      "[1000]\ttrain-merror:0.116933\ttrain-merror:0.116933\n",
      "[1100]\ttrain-merror:0.108165\ttrain-merror:0.108165\n",
      "[1199]\ttrain-merror:0.098817\ttrain-merror:0.098817\n",
      "[[1.         0.99804248]\n",
      " [0.99804248 1.        ]]\n",
      "logloss 0.5248963679885958\n",
      "ac 0.901183056934615\n",
      "mae 0.03258629932951513\n",
      "[0]\ttrain-merror:0.349952\ttrain-merror:0.349952\n",
      "[100]\ttrain-merror:0.270149\ttrain-merror:0.270149\n",
      "[200]\ttrain-merror:0.242844\ttrain-merror:0.242844\n",
      "[300]\ttrain-merror:0.21501\ttrain-merror:0.21501\n",
      "[400]\ttrain-merror:0.189976\ttrain-merror:0.189976\n",
      "[500]\ttrain-merror:0.173233\ttrain-merror:0.173233\n",
      "[600]\ttrain-merror:0.158762\ttrain-merror:0.158762\n",
      "[700]\ttrain-merror:0.14672\ttrain-merror:0.14672\n",
      "[800]\ttrain-merror:0.136316\ttrain-merror:0.136316\n",
      "[900]\ttrain-merror:0.126175\ttrain-merror:0.126175\n",
      "[1000]\ttrain-merror:0.116457\ttrain-merror:0.116457\n",
      "[1100]\ttrain-merror:0.107003\ttrain-merror:0.107003\n",
      "[1199]\ttrain-merror:0.099028\ttrain-merror:0.099028\n",
      "[[1.         0.99806065]\n",
      " [0.99806065 1.        ]]\n",
      "logloss 0.5243530478628512\n",
      "ac 0.9009717967677194\n",
      "mae 0.03261138592710829\n"
     ]
    }
   ],
   "source": [
    "tmp_pre = np.zeros((len(test_x),4))\n",
    "sub2 = pd.DataFrame()\n",
    "\n",
    "xg_train = xgb.DMatrix( train_x, label=train_y)\n",
    "train_x = xgb.DMatrix(train_x)\n",
    "test_x = xgb.DMatrix(test_x)\n",
    "# setup parameters for xgboost\n",
    "for rand_seed in [500,1212,2019,51421,93693]:\n",
    "    param = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'multi:softprob',  # 多分类的问题\n",
    "        'num_class': 4,               # 类别数，与 multisoftmax 并用\n",
    "        'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "        'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "        'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "        'subsample': 0.9,              # 随机采样训练样本\n",
    "        'colsample_bytree': 0.9,       # 生成树时进行的列采样\n",
    "        'min_child_weight': 3,\n",
    "        'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "        'eta': 0.007,                  # 如同学习率\n",
    "        'seed': rand_seed,\n",
    "        'nthread': 4,                  # cpu 线程数\n",
    "    }\n",
    "\n",
    "    watchlist = [ (xg_train,'train'), (xg_train, 'train') ]\n",
    "    num_round = 1200\n",
    "    bst = xgb.train(param, xg_train, num_round, watchlist ,verbose_eval=100);\n",
    "    # get prediction\n",
    "    oof_xgb = bst.predict(train_x)\n",
    "#     prediction_xgb += bst.predict( test_x )/5\n",
    "\n",
    "    prediction = bst.predict( test_x )\n",
    "    print(np.corrcoef(prediction[:,0],tmp_pre[:,0] ) )  ##比较不同种子下相似度 0.991 lgb模型相似度可能高些\n",
    "    \n",
    "    tmp_pre = bst.predict( test_x )\n",
    "\n",
    "    \n",
    "    sub = test[['Group']]\n",
    "    prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "    for i, f in enumerate(prob_cols):\n",
    "        sub[f] = prediction[:, i]\n",
    "    sub2 = pd.concat([sub,sub2],sort = False)    \n",
    "    \n",
    "    print('logloss',log_loss(pd.get_dummies(train_y).values, oof_xgb))\n",
    "    print('ac',accuracy_score(train_y, np.argmax(oof_xgb,axis=1)))\n",
    "    print('mae',1/(1 + np.sum(np.absolute(np.eye(4)[train_y] - oof_xgb))/480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(prob_cols):\n",
    "    sub2[f+'_rank'] = sub2.groupby('Group')[f].rank(method='first')\n",
    "    sub2[f+'_rank'] = sub2[f+'_rank']-125\n",
    "    sub2[f+'_rank'] = sub2[f+'_rank'].apply(lambda x: -(0.8/125/125/250)*x*x+1.4/250 )\n",
    "    sub2[f+'_rank'] = sub2[f+'_rank']  #*sub['gcnt']\n",
    "    sub2[f] = sub2[f]*sub2[f+'_rank']\n",
    "for i in prob_cols:\n",
    "    sub2[i] = sub2.groupby('Group')[i].transform('sum')  \n",
    "sub2 = sub2[list(submit)].drop_duplicates().reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2['all_sum'] = sub2[prob_cols].sum(axis=1)\n",
    "for i in prob_cols:\n",
    "    sub2[i] = sub2[i]/sub2['all_sum']\n",
    "sub2['Group'] = submit['Group']\n",
    "sub2[list(submit)].to_csv('result_3/xgb_12.csv',index=False) ###0.70104530000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv('../data/first_round_testing_data.csv')\n",
    "submit = pd.read_csv('../data/submit_example.csv')\n",
    "sub = test_sub[['Group']]\n",
    "prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "\n",
    "for i, f in enumerate(prob_cols):\n",
    "    sub[f] = prediction_xgb[:, i]\n",
    "for i in prob_cols:\n",
    "    sub[i] = sub.groupby('Group')[i].transform('mean')\n",
    "sub = sub.drop_duplicates()\n",
    "sub.to_csv(\"result/xgb_23.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = pd.read_csv('../data/first_round_testing_data.csv')\n",
    "submit = pd.read_csv('../data/submit_example.csv')\n",
    "sub = test_sub[['Group']]\n",
    "\n",
    "prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "\n",
    "for i, f in enumerate(prob_cols):\n",
    "    sub[f] = prediction_xgb[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('xgb_0.700.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
